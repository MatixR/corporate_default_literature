---
title: "Literature review of corporate default prediction "
author: "Benjamin Christoffersen"
date: "`r format(Sys.time(), 'Updated on %B %d, %Y')`"
output: 
  function(...) rmarkdown::html_document(..., css=c("css/jquery.dataTables.min.css", "css/fixedColumns.dataTables.min.css", "css/style.css")):
    toc: false
---

```{r setup, include=FALSE}
options(scipen = 100, digits = 3)
```

## My rating
My rating is my subject score based on the following criteria:

* Relevance if you are building bankruptcy prediction models and implications of/motvation to use such models.
* Large data samples (not just listed firms).
* Non-financial firms since there is a general consensus in the literature that these firms should be modeled separately.
* Different models, method etc.
* Different countries or data sets that are commonly used in literature.

Details of the rating are explaind in "My review". An empty rating means that I have not yet read the paper/document but it is on my TODO list or that I have read the paper/document but not written a review yet

## Further notes
The word logistic regression will be used both for papers using probit models and logistic regression. The logic is that there is usually little difference in practice between the two.

## Review table

```{r load_data, echo = FALSE}
# Read in data
fname_data <- "data/review_data.csv"
review_data <- read.csv(
  fname_data, header = T, sep = ",", quote = '"', 
  stringsAsFactors = F, fileEncoding = "UTF-8", na.strings = "")
actual_headers <- read.csv(
  fname_data, header = F, sep = ",", quote = '"', 
  stringsAsFactors = F, nrows = 1, fileEncoding = "UTF-8")
colnames(review_data) <- actual_headers

fname_bib <- "data/ref.bib"
RefManageR::BibOptions(check.entries = FALSE)
bib <- RefManageR::ReadBib(fname_bib)
```

```{r, echo = FALSE, eval = FALSE}
#####
# Define function to search on Crossref
find_ref <- function(.title, journal = NA_character_){
  .query <- .title
  if(!is.na(journal))
    .query <- paste(.query, journal)
  cat("Looking for", sQuote(.query), "on Crossref...\n")
  
  try({
    res <- RefManageR::ReadCrossRef(.query, limit = 5)
    
    cat("Results are:\n")
    for(i in rev(seq_along(res))){
      cat("(", i, ") ", sep = "")
      tryCatch(
        print(res[[i]], .opts = list(style = "text", bib.style = "authoryear")),
        error = function(...)
          print(res[[i]], .opts = list(style = "Bibtex")))
      cat("\n")
    }
    
    cat("Select the one that match with", sQuote(.query), "\n")
    .pick <- as.integer(readline("Enter value that match (-1 for no match): "))
    
    out <- if(.pick %in% seq_len(length(res))){
      res <- res[[.pick]]
      cat("Adding:\n")
      print(res, .opts = list(style = "Bibtex"))
      list(
        Year = res$year, Journal = res$journal, Url = res$url, doi = res$doi,
        bibentry = res, Authors = paste0(res$author, collapse = ", "),
        Publisher = res$publisher)
    } else {
      cat("No valid value. No action taken\n")
      NULL
    }
    cat("\n")
    
    return(out)
  }, TRUE)
  
  cat("Failed. Error messages is:\n")
  print(.Last.value)
  
  NULL
}

save_exp <- expression({
  write.csv(
          review_data, file = fname_data,
          quote = TRUE, row.names = FALSE, fileEncoding = "UTF-8", na = "")
  RefManageR::WriteBib(bib, fname_bib)
})

n_new <- 0
for(i in 1:nrow(review_data)){
  if(is.na(review_data$doi[i]) || review_data$doi[i] == ""){
    out <- find_ref(review_data$`Article name`[i], review_data$Journal[i])
    
    if(!is.null(out)){
      bib <- c(bib, out$bibentry)
      
      out <- out[!names(out) %in% "bibentry"]
      stopifnot(all(names(out) %in% colnames(review_data)))
      for(n in names(out)){
        if((is.na(review_data[i, n]) || 
            is.na(review_data[i, n]) == "") && 
           !is.null(out[[n]]))
          review_data[i, n] <- out[[n]]
      }
      
      review_data[i, "Key"] <- names(bib)[length(bib)]
      
      n_new <- n_new + 1
      if(n_new %% 5 == 0)
        eval(save_exp, envir = environment())
    }
  }
}
eval(save_exp, envir = environment())
```

```{r ref_man_setup, echo = FALSE}
unloadNamespace("RefManageR")
library(RefManageR)
bib <- RefManageR::ReadBib(fname_bib, check = FALSE)
RefManageR::BibOptions(
  check.entries = FALSE, style = "markdown", cite.style = "authoryear",
  bib.style = "numeric")
```

```{r format_data, echo = FALSE}
#####
# Replace the model abbrevations 
model_abb <- read.table("data/model_def", sep = ",", header = F, stringsAsFactors = F)
review_data$Models <- sapply(review_data$Models, function(x){
  if(is.na(x))
    return("")
  
  ms <- unlist(strsplit(x, ", "))
  ms_match <- match(ms, model_abb[, 1])
  if(any(is.na(ms_match))){
      stop("Could not find ", paste0(
          "'", ms[is.na(ms_match)], "'", collapse = " "))
  }
  paste0(model_abb[ms_match, 2], collapse = "\n")
})

stopifnot(!any(duplicated(review_data$`Article name`)))

#####
# Make url for google scholar search
review_data$g_scholar <-  mapply(
  title = review_data$`Article name`,
  publisher = review_data$Journal,
  
  function(title, publisher){
    publisher <- 
      if(!is.na(publisher))
        paste0(
          '&as_publication="', gsub("\\ ", "+", publisher), '"') else ""
    paste0(
      'https://scholar.google.com/scholar?as_q=&as_epq="',
      gsub("\\ ", "+", title), '"',  publisher, "&hl=en")
  })

#####
# Order rows by my rating
review_data <- review_data[order(
  review_data$`My rating (1: best, 5: worst)`, 
  -review_data$Year), ]

#####
# Formating

# replace linebreaks by br
# We also correct for invalid dash entries
for(s in colnames(review_data)[sapply(review_data, is.character)]){
  review_data[[s]] <- gsub("\\s*\\n\\s*", "\\ \\<br\\> \\",review_data[[s]])
  review_data[[s]] <- gsub("â€“", "-", review_data[[s]])
}

# Wrap links in "a" tags
for(s in c("g_scholar", "Url")){
  review_data[[s]] <- 
    ifelse(is.na(review_data[[s]]), 
           rep("", nrow(review_data)), 
           paste0("<a target='_blank' href='", review_data[[s]], "' >Link</a>"))
}
```

```{r make_data_tbl, echo=FALSE,results='asis', warning = FALSE}
#####
# Change column order
review_data <- review_data[, !colnames(review_data) %in% "Publisher"]
ord <- c("Authors", "Year", "Article name",  "Journal", "Models", "My rating (1: best, 5: worst)", "My review", "g_scholar", "Data source/set", "Sampling", "Sample size (failure / non-failure)", "Outcome", "Url", "doi", "Key")
stopifnot(all(ord %in% colnames(review_data)))

review_data <- review_data[, match(ord, colnames(review_data))]

#####
# Function to print 
cat <- function(
  ..., file = "", sep = " ", fill = FALSE, labels = NULL, append = FALSE){
  x <- list(...)
  x <- x[!is.na(x)]
  
  do.call(base::cat, c(x, file = file, sep = sep, fill = fill, labels = labels, 
                       append = append))
}

fname <- "tbl_file.html" 
unlink(fname)
f <- file(fname, open = "at")

p <- function(x, lvl = 0, tag, file = f){
  if(missing(tag)){
    pb <- ""
    pa <- ""
  } else {
    pb <- paste0("<", tag, ">")
    pa <- paste0("</", tag, ">")
  }
  
  cat(rep("\t", lvl), pb, x, pa, "\n", sep = "", file = file)
}

# Table tag
p("<!--html_preserve-->")
p('<table id="review_tbl" class="display">')

#####
# Header
p("<thead>", 1)
p("<tr>", 2)
cnames <- colnames(review_data)
cnames_change <- c(
  "My rating (1: best, 5: worst)" = "My rating<br>(1: best, 5: worst)",
  "g_scholar" = "Google scholar query",
  "Sample size (failure / non-failure)" = 
    "Sample size<br>(failure / non-failure)",
  "Url" = "Crossref Url",
  "doi" = "Crossref doi",
  "Key" = "Bibkey")
stopifnot(all(names(cnames_change) %in% cnames))
cnames[match(names(cnames_change), cnames)] <- unname(cnames_change)

invisible(sapply(cnames, p, lvl = 3, tag = "th"))
p("</tr>", 2)
p("</thead>", 1)

#####
# Content 
p("<tbody>", 1)
invisible(apply(review_data, 1, function(x){
  p("<tr>", 2)
  sapply(x, p, lvl = 3, tag = "td")
  p("</tr>", 2)
}))
p("</tbody>", 1)

# Table tag
p('</table>') 
p("<!--/html_preserve-->")

close(f)

# Print content of file
cat(readLines(fname), sep = "\n")

#####
# Make javascript to make table
jname <- "table.js"
unlink(jname)
f <- file(jname, open = "at")
p("<!--html_preserve-->")
p("<script src='js/jquery.dataTables.min.js'></script>")
p("<script src='js/dataTables.fixedColumns.min.js'></script>")
p('<script type="text/javascript">')

p('// Sort function for NA from https://datatables.net/forums/discussion/7446/numeric-sort-with-na-in-some-cells')
p("$.fn.dataTableExt.oSort['numeric_ignore_nan-asc'] = function(x,y) {")
p('if (isNaN(x) && isNaN(y)) return ((x < y) ? 1 : ((x > y) ? -1 : 0));', 1)
p('if (isNaN(x)) return 1;', 1)
p('if (isNaN(y)) return -1;', 1)
p("x = parseFloat( x );", 1)
p("y = parseFloat( y );", 1)
p("return ((x < y) ? -1 : ((x > y) ? 1 : 0));", 1)
p("};")

p("$.fn.dataTableExt.oSort['numeric_ignore_nan-desc'] = function(x,y) {")
p("if (isNaN(x) && isNaN(y)) return ((x < y) ? 1 : ((x > y) ? -1 : 0));", 1)
p("if (isNaN(x)) return 1;", 1)
p("if (isNaN(y)) return -1;", 1)
p("x = parseFloat( x );", 1)
p("y = parseFloat( y );", 1)
p("return ((x < y) ? 1 : ((x > y) ? -1 : 0));", 1)
p("};")

p("$(document).ready(function() {")
p("$('#review_tbl').DataTable( {", 1)
p('"scrollY": "800px",', 2)
p('"scrollX": true,', 2)
p('"pageLength": 4,', 2)
p('"lengthMenu": [4, 8, 12],', 2)
p('"scrollCollapse": true,', 2)
p('"scrollCollapse": true,', 2)
p('fixedColumns: { leftColumns: 2 },', 2)
p(paste0(
  '"order": [[', 
  which(colnames(review_data) == "My rating (1: best, 5: worst)") - 1, 
  ", 'asc'], [",
  which(colnames(review_data) == "Year") - 1,
  ", 'desc']],"), 2)

#####
# Setup columnDefs
columnDefs <- c(
  "Article name" = '"className": "dt-body-left", "width": "18em", "searchable": true,', 
  "Authors" = '"className": "dt-body-left", "width": "15em", "searchable": true,',
  "Journal" = '"className": "dt-body-left", "width": "10em", "searchable": true,', 
  "Models" = '"className": "dt-body-left", "width": "20em", "searchable": true,', 
  "My rating (1: best, 5: worst)" = 
    '"className": "dt-body-center", "width": "9em", "type": "numeric_ignore_nan"', 
  "My review" = '"className": "dt-body-left", "width": "40em"', 
  "g_scholar" = '"className": "dt-body-center", "width": "5em"', 
  "Url" = '"className": "dt-body-center", "width": "5em"',
  "Data source/set" = '"className": "dt-body-left", "width": "40em", "searchable": true,', 
  "Sampling" = '"className": "dt-body-left", "width": "20em", "searchable": true,', 
  "Sample size (failure / non-failure)" = 
    '"className": "dt-body-left", "width": "20em", "searchable": true,', 
  "Year" = '"className": "dt-body-right", "width": "5em", "type": "numeric_ignore_nan"',
  "Outcome" = '"className": "dt-body-left", "width": "20em", "searchable": true',

  "doi" = '"className": "dt-body-left", "width": "10em"',
  "Key" = '"className": "dt-body-left", "width": "1em"'
  )

stopifnot(setequal(names(columnDefs), colnames(review_data)))
columnDefs <- columnDefs[match(colnames(review_data), names(columnDefs))]
columnDefs <- 
  paste0('{ "targets": ', 0:(length(columnDefs) - 1), ", ",  columnDefs, ' }')
columnDefs[-length(columnDefs)] <- 
  paste0(columnDefs[-length(columnDefs)], ", ")

p('"columnDefs": [', 2)
invisible(sapply(columnDefs, p, 3))
p(']', 2)


p("});", 1)
p("} );")

p('</script>')
p("<!--/html_preserve-->")

close(f)

# Print content of file
cat(readLines(jname), sep = "\n")
```

# .bib file

<div id="bib_file" style="overflow-y: scroll; height:400px; font-family: 'Lucida Console'; border: 1px solid #ccc; border-radius: 4px; background-color: white; padding: 9.5px; margin: 0 0 10px;" >

```{r refs, results = "asis", echo = FALSE}
cat("<!--html_preserve-->")
cat(gsub("^\\ \\ ", "&emsp;", htmltools::htmlEscape(readLines(fname_bib))), sep ="<br>")
cat("<!--/html_preserve-->")
```

</div>

