---
title: "Literature review of corporate default prediction "
author: "Benjamin Christoffersen"
date: "`r format(Sys.time(), 'Updated on %B %d, %Y')`"
output: 
  function(...) rmarkdown::html_document(..., css=c("css/jquery.dataTables.min.css", "css/style.css")):
    toc: false
---

```{r setup, include=FALSE}
options(scipen = 100, digits = 3)
```

## My rating
My rating is my subject score based on the following criteria:

* Relevance if you are building bankruptcy prediction models
* Large data samples (not just listed firms)
* Non-financial firms since there is a general consensus in the literature that these firms should be modeled separately
* Different models, method etc. 
* Different countries or data sets that are commonly used in literature
* Credit scoring is not considered unless I find the paper relevant to prediction

Details of the rating are explaind in "My review". An NA rating means that I have not yet read the paper/document but it is on my TODO list or that I have read the paper/document but not written a review yet

## Further notes
The word logistic regression will be used both for papers using probit models and logistic regression. The logic is that there is usually little difference in practice between the two

TODO: write explanation for frailty versus contagion

## Review table

```{r, echo=FALSE,message=FALSE, warning=FALSE, error=TRUE, results='asis'}
# Read in data
review_data <- read.csv("data/review_data.csv", header = T, sep = ",", quote = '"', 
                        stringsAsFactors = F, fileEncoding = "UTF-8-BOM")
actual_headers <- read.csv("data/review_data.csv", header = F, sep = ",", quote = '"', 
                           stringsAsFactors = F, nrows = 1, fileEncoding = "UTF-8-BOM")

colnames(review_data) <- actual_headers

# Replace the model abbrevations 
model_abb <- read.table("data/model_def", sep = ",", header = F, stringsAsFactors = F)
review_data$Models <- sapply(review_data$Models, function(x){
    ms <- unlist(strsplit(x, ", "))
    ms_match <- match(ms, model_abb[, 1])
    if(any(is.na(ms_match))){
        stop("Could not find ", paste0(
            "'", ms[is.na(ms_match)], "'", collapse = " "))
    }
    paste0(model_abb[ms_match, 2], collapse = "\n")
})

# Find further article information
if(F){ # Set to FALSE if data should be loaded from output folder
  source("R/google_scholar_info.R")
  
  log_file <- file("output/google_data.log", open = "wt")
  sink(log_file, type = "message")
  options(warn = 1)
  google_dat <- apply(
    review_data[, c("Article name", "Publisher")], 1, function(x){
      message("Procesing ", paste0(x, collapse = ", "), "...")
      get_google_scholar_info(x[1], x[2])
    })
  sink(file = NULL, type = "message")
  close(log_file)
  
  google_dat <- data.frame(matrix(unlist(google_dat), nrow = length(google_dat), 
                                  byrow = T, dimnames = 
                                    list(NULL, names(google_dat[[1]]))), 
                           stringsAsFactors = F)
  
  if(all(is.na(google_dat)))
    stop("Likely got 503 errors as google banned the ip for a few days")
  
  write.table(cbind(review_data[, c("Article name", "Publisher")],
                    google_dat), 
              "output/google_data", row.names = F, col.names = T)
} else {
  google_dat <- read.table("output/google_data", row.names = NULL, 
                           stringsAsFactors = F, header = T, allowEscapes = T)
  
  google_dat <- 
    google_dat[match(review_data$`Article name`, google_dat$Article.name), 
               c("journal_url", "year", "n_citations", "abstract", "related_articles")]
}

google_dat[, c("year", "n_citations")] <- 
  sapply(google_dat[, c("year", "n_citations")], as.numeric)

# Put urls into a <a> tag
google_dat$journal_url <- ifelse(
  is.na(google_dat$journal_url), 
  rep(NA, nrow(google_dat)), 
  paste0("<a target='_blank' href='", google_dat$journal_url, "' >Link</a>"))

google_dat$related_articles <- ifelse(
  is.na(google_dat$related_articles), 
  rep(NA, nrow(google_dat)), 
  paste0("<a target='_blank' href='", google_dat$related_articles, "' >Link</a>"))

# format column names
google_dat <- plyr::rename(
  google_dat, c("journal_url" = "link", "n_citations" = "Citations", 
                "related_articles" = "Google Scholar"))

review_data <- cbind(review_data, google_dat)

# Order rows by my train and number of citations
review_data <- 
  if(!all(is.na(review_data$Citations)))
    review_data[order(review_data$`My rating (1: best, 5: worst)`, 
                      -review_data$Citations), ] else
                        review_data[order(review_data$`My rating (1: best, 5: worst)`), ]

# Order columns and define alignment
align_n_c_order <- c(
  "Article name" = "left", 
  "My rating (1: best, 5: worst)" = "right", 
  "Citations" = "right", 
  "Google Scholar" = "right",
  "abstract" = "left",
  "year" = "right", 
  "link" = "left",
  "My review" = "left", 
  "Outcome" = "left", 
  "Sample size (failure / non-failure)" = "left",
  "Models" = "left", 
  "Data source/set" = "left", 
  "Sampling" = "left",
  "Publisher" = "left")

split_cells <- c(
  "Article name" = 25, 
  "My rating (1: best, 5: worst)" = 20, 
  "Citations" = 10, 
  "abstract" = 50,
  "My review" = 50, 
  "Outcome" = 50, 
  "Sample size (failure / non-failure)" = 20,
  "Models" = 25, 
  "Data source/set" = 50, 
  "Sampling" = 50,
  "year" = 4, 
  "Publisher" = 20,
  "link" = 50, 
  "Google Scholar" = 50)

review_data <- 
  review_data[, names(align_n_c_order)]
row.names(review_data) <- NULL

# Final formating of header 
review_data <- plyr::rename(review_data, c(
  "My rating (1: best, 5: worst)" = "My rating<br>(1: best, 5: worst)",
  "Sample size (failure / non-failure)" = "Sample size<br>(failure / non-failure)"
))

# Replace line breaks with br tags
is_char <- sapply(review_data, is.character)
review_data[, is_char] <- 
  sapply(review_data[, is_char], gsub, pattern = "\\s*\\n\\s*",
         replacement = "\\ \\<br\\> \\")

# We also correct for invalid dash entries
review_data[, is_char] <- 
  sapply(review_data[, is_char], gsub, pattern = "â€“",
         replacement = "-")

# Print table
pander::panderOptions('knitr.auto.asis', FALSE)
pander::pandoc.table(review_data,
                     keep.line.breaks = T, 
                     justify = align_n_c_order, 
                     split.table = Inf,
                     split.cells = split_cells[names(align_n_c_order)],
                     style = 'multiline')
```

<script src="js/jquery.dataTables.min.js"></script>

<script type="text/javascript">
// Sort function for NA from https://datatables.net/forums/discussion/7446/numeric-sort-with-na-in-some-cells
$.fn.dataTableExt.oSort['numeric_ignore_nan-asc'] = function(x,y) {
if (isNaN(x) && isNaN(y)) return ((x < y) ? 1 : ((x > y) ? -1 : 0));

if (isNaN(x)) return 1;
if (isNaN(y)) return -1;

x = parseFloat( x );
y = parseFloat( y );
return ((x < y) ? -1 : ((x > y) ? 1 : 0));
};

$.fn.dataTableExt.oSort['numeric_ignore_nan-desc'] = function(x,y) {
if (isNaN(x) && isNaN(y)) return ((x < y) ? 1 : ((x > y) ? -1 : 0));

if (isNaN(x)) return 1;
if (isNaN(y)) return -1;

x = parseFloat( x );
y = parseFloat( y );
return ((x < y) ? 1 : ((x > y) ? -1 : 0));
};

$(document).ready(function(){
  $("#review-table > table > colgroup").remove();
  $("#review-table > table").removeAttr('width');
  $("#review-table > table").DataTable({
    "scrollY": "800px",
		"scrollX": true,
		"autoWidth": false,
		"pageLength": 4,
		"lengthMenu": [ 4, 10, 50, 100 ],
		"order": [[1, "asc" ], [2, "desc" ]],
    "columnDefs": [
      { "width": "18em", "targets": 0 },  // article name
      { "width": "9em", "type": "numeric_ignore_nan", "targets": 1 },   // rating
      { "width": "5em", "type": "numeric_ignore_nan", "targets": 2 },   // citations
      { "width": "5em", "type": "numeric_ignore_nan", "targets": 3 },   // google scholar
      { "width": "30em", "targets": 4 },  // abstact
      { "width": "5em", "targets": 5 },   // year
      { "width": "6em", "targets": 6 },   // link
      { "width": "30em", "targets": 7 },  // review
      { "width": "20em", "targets": 8 },  // outcome
      { "width": "20em", "targets": 9 },  // sample size
      { "width": "20em", "targets": 10 }, // models
      { "width": "30em", "targets": 11 }, // data set
      { "width": "20em", "targets": 12 }, // sampling
      { "width": "10em", "targets": 13 }  // publisher
    ]
  });
});
</script>